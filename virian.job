#!/bin/bash

#SBATCH --job-name=virian        # Job name
#SBATCH --output=logs/%j-%x.out  # Name of output file (%j expands to jobId)
#SBATCH --cpus-per-task=1        # Schedule one core
#SBATCH --time=01:00:00          # Run time (hh:mm:ss)
#SBATCH --partition=brown        # Run on either the Red or Brown queue
#SBATCH --gres=gpu               # Schedule a GPU
#SBATCH --mem-per-cpu=16000      # <value bigger than you've requested before>


module --ignore-cache load CUDA/10.2.89-GCC-8.3.0
source env/bin/activate
python main.py --train
# python -c 'import torch; print(torch.cuda.is_available())'
# docker run --rm --mount type=bind,source=$HOME/virian/data,target=/usr/src/data nlp
